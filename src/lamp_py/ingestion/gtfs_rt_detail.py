from abc import ABC
from abc import abstractmethod
from typing import Optional, List, Tuple

import pyarrow
import pyarrow.compute as pc


class GTFSRTDetail(ABC):
    """
    Abstract Base Class for all GTFSRTDetail implementations.

    GTFSRTDetail classes must implement all methods and properties that are
    defined.
    """

    def flatten_schema(self, table: pyarrow.table) -> pyarrow.table:
        """flatten pyarrow table if struct column type exists"""
        for field in table.schema:
            if str(field.type).startswith("struct"):
                return self.flatten_schema(table.flatten())
        return table

    def explode_table_column(
        self, table: pyarrow.table, column: str
    ) -> pyarrow.table:
        """explode list-like column of pyarrow table by creating rows for each list value"""
        other_columns = list(table.schema.names)
        other_columns.remove(column)
        indices = pc.list_parent_indices(table[column])
        return pyarrow.concat_tables(
            [
                table.select(other_columns)
                .take(indices)
                .append_column(
                    pyarrow.field(
                        column, table.schema.field(column).type.value_type
                    ),
                    pc.list_flatten(table[column]),
                ),
                table.filter(
                    pc.list_value_length(table[column]).is_null()
                ).select(other_columns),
            ],
            promote=True,
        )

    def transform_for_write(self, table: pyarrow.table) -> pyarrow.table:
        """modify table schema before write to parquet"""
        return self.flatten_schema(table)

    @property
    @abstractmethod
    def import_schema(self) -> pyarrow.schema:
        """Get the import schema for the parquet table generated by this config"""

    @property
    def table_sort_order(self) -> Optional[List[Tuple[str, str]]]:
        """
        Provide list of fields to sort pyarrow table before writing to parquet

        table_sort_order should be configured to optimize parquet file size
        when writing to disk

        Currently specified sort orders were determined by a small amount of experimentation

        TODO: perform additional experiments to optimize sort order of all parquet file types  # pylint: disable=fixme
        """
        return None
